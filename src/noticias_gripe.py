
import requests
from bs4 import BeautifulSoup
import streamlit as st

# Simulando um navegador
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36',
    'Accept-Language': 'en-US,en;q=0.9,pt-BR;q=0.8,pt;q=0.7',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive'
}


# Fun√ß√£o para verificar se a not√≠cia √© relacionada √† gripe
def is_gripe_related(title, description):
    '''
    Descri√ß√£o:
    Verifica se uma not√≠cia est√° relacionada a gripe com base em palavras-chave presentes no t√≠tulo ou descri√ß√£o.

    Par√¢metros:

    title (str): O t√≠tulo da not√≠cia.
    description (str): A descri√ß√£o da not√≠cia.
    Retorno:

    (bool): True se alguma palavra-chave estiver presente no t√≠tulo ou na descri√ß√£o, caso contr√°rio, False.
    Palavras-chave utilizadas:

    'gripe', 'influenza', 'resfriado', 'covid'.

    '''
    keywords = ['gripe', 'influenza', 'resfriado', 'covid']
    return any(keyword.lower() in title.lower() or keyword.lower() in description.lower() for keyword in keywords)

# Fun√ß√£o para extrair informa√ß√µes sobre a gripe (site do governo)
def scrape_gripe_info():
    '''
    Descri√ß√£o:
    Extrai informa√ß√µes sobre gripe diretamente do site oficial do Governo do Brasil.

    Par√¢metros:

    Nenhum.
    Retorno:

    (list[str]): Lista de par√°grafos com informa√ß√µes relevantes sobre gripe.
    Exce√ß√µes:

    Gera uma exce√ß√£o se a p√°gina n√£o puder ser acessada.
    Depend√™ncias:

    requests, BeautifulSoup.

    '''
    url = 'https://www.gov.br/saude/pt-br/assuntos/saude-de-a-a-z/g/gripe-influenza'
    response = requests.get(url, headers=HEADERS)
    
    if response.status_code != 200:
        raise Exception(f"Erro ao acessar o site: {response.status_code}")
    
    soup = BeautifulSoup(response.content, 'html.parser')
    paragraphs = soup.find_all('p')
    
    gripe_info = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]
    return gripe_info


# Fun√ß√£o para coletar not√≠cias da CNN Brasil
def scrape_cnn_news():
    '''
    Descri√ß√£o:
    Coleta not√≠cias relacionadas √† gripe publicadas na CNN Brasil.

    Par√¢metros:

    Nenhum.
    Retorno:

    (list[dict]): Lista de not√≠cias, onde cada not√≠cia cont√©m:
    title (str): T√≠tulo da not√≠cia.
    link (str): URL da not√≠cia.
    description (str): Descri√ß√£o ou resumo da not√≠cia.
    date (str): Data de publica√ß√£o.
    Exce√ß√µes:

    Gera uma exce√ß√£o se a p√°gina da CNN n√£o puder ser acessada.
    Depend√™ncias:

    requests, BeautifulSoup.
    Nota:

    Filtra as not√≠cias utilizando palavras-chave relacionadas √† gripe.
    '''
    # URL do site
    url = "https://www.cnnbrasil.com.br/tudo-sobre/gripe/"
    
    # Cabe√ßalho para evitar bloqueios
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36"
    }
    
    # Requisi√ß√£o √† p√°gina
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        raise Exception(f"Erro ao acessar o site: {response.status_code}")
    
    # Parse do conte√∫do HTML
    soup = BeautifulSoup(response.content, "html.parser")
    
    # Selecionar o container principal das not√≠cias
    news_items = soup.find_all("li", class_="home__list__item")
    news_data = []
    
    for item in news_items:
        # Extrair o t√≠tulo
        title_tag = item.find("h3", class_="news-item-header__title")
        title = title_tag.text.strip() if title_tag else "T√≠tulo n√£o encontrado"
        
        # Extrair o link
        link_tag = item.find("a", href=True)
        link = link_tag["href"] if link_tag else "Link n√£o encontrado"
        
        # Extrair a data de publica√ß√£o
        date_tag = item.find("span", class_="home__title__date")
        date = date_tag.text.strip() if date_tag else "Data n√£o encontrada"
        
        # Filtrar por relev√¢ncia (gripe)
        if "gripe" or "influeza" or "resfriado" or "covid" in title.lower():
            news_data.append({
                "title": title,
                "link": link,
                "description": title,  
                "date": date
            })
    
    return news_data

# Fun√ß√£o para coletar not√≠cias do G1
def scrape_g1_news(state, city=None):
    '''
    Descri√ß√£o:
    Busca not√≠cias relacionadas √† gripe no G1 com base no estado e, opcionalmente, no munic√≠pio.

    Par√¢metros:

    state (str): Nome do estado para busca.
    city (str, opcional): Nome do munic√≠pio para busca.
    Retorno:

    (list[dict]): Lista de not√≠cias, onde cada not√≠cia cont√©m:
    title (str): T√≠tulo da not√≠cia.
    link (str): URL da not√≠cia.
    description (str): Resumo da not√≠cia.
    date (str): Data de publica√ß√£o.
    Exce√ß√µes:

    Gera uma exce√ß√£o se a p√°gina do G1 n√£o puder ser acessada.
    Depend√™ncias:

    requests, BeautifulSoup.

    '''
    search_query = f"gripe {state}" + (f" {city}" if city else "")
    url = f"https://g1.globo.com/busca/?q={search_query}"
    response = requests.get(url, headers=HEADERS)

    if response.status_code != 200:
        raise Exception(f"Erro ao acessar a p√°gina do G1 (Status code: {response.status_code})")
    
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Selecionando os elementos de not√≠cia
    news_elements = soup.find_all('div', class_='widget--info__text-container')
    if not news_elements:
        return []

    news_data = []
    for element in news_elements:
        title_tag = element.find('div', class_='widget--info__title')
        link_tag = element.find('a', href=True)
        description_tag = element.find('p', class_='widget--info__description')
        date_tag = element.find('div', class_='widget--info__meta')

        if title_tag and link_tag:
            title = title_tag.text.strip()
            link = link_tag['href']
            description = description_tag.text.strip() if description_tag else "Descri√ß√£o n√£o dispon√≠vel"
            date = date_tag.text.strip() if date_tag else "Data n√£o informada"

            # Aplicar filtro por dengue
            if is_gripe_related(title, description):
                news_data.append({
                    'title': title,
                    'link': link,
                    'description': description,
                    'date': date
                })

    return news_data

# Fun√ß√£o para exibir as not√≠cias no Streamlit
def show_news(news, title):
    '''
    Descri√ß√£o:
    Exibe not√≠cias formatadas no Streamlit.

    Par√¢metros:

    news (list[dict]): Lista de not√≠cias para exibi√ß√£o.
    title (str): T√≠tulo da se√ß√£o de not√≠cias.
    Retorno:

    Nenhum (exibi√ß√£o direta no Streamlit).
    Comportamento:

    Exibe t√≠tulo, link clic√°vel, data de publica√ß√£o e descri√ß√£o de cada not√≠cia.
    Exibe mensagem "Nenhuma not√≠cia encontrada" caso a lista esteja vazia.
    Depend√™ncias:

    streamlit.
    '''
    st.subheader(title)
    if not news:
        st.write("Nenhuma not√≠cia encontrada.")
        return
    
    for item in news:
        st.markdown(f"**[{item['title']}]({item['link']})**")
        st.write(f"*Publicado em: {item['date']}*")
        st.write(f"{item['description']}")
        st.write("---")

# Streamlit App
def noticias_informacoes_gripe():
    '''
    Descri√ß√£o:
    Aplicativo principal em Streamlit para exibir informa√ß√µes e not√≠cias sobre gripe.

    Par√¢metros:

    Nenhum.
    Fluxo:

    Carrega informa√ß√µes gerais sobre gripe do site do governo.
    Exibe not√≠cias gerais sobre gripe da CNN Brasil.
    Exibe not√≠cias espec√≠ficas do G1 com base no estado e munic√≠pio.
    Bot√µes no Streamlit:

    "Carregar Informa√ß√µes sobre gripe".
    "Carregar Not√≠cias Gerais".
    "Carregar Not√≠cias por Munic√≠pio".
    Depend√™ncias:

    streamlit, fun√ß√µes auxiliares como scrape_gripe_info, scrape_cnn_news, scrape_g1_news.
    Notas:

    Usa vari√°veis globais como MUNICIPIO_USUARIO_GRIPE para determinar o munic√≠pio selecionado.
    Lida com exce√ß√µes ao acessar dados ou p√°ginas externas.

    '''
    st.title("üîç Not√≠cias e Informa√ß√µes sobre gripe üîç")
    
    # Informa√ß√µes gerais
    if st.button("Carregar Informa√ß√µes sobre gripe"):
        try:
            informacoes = scrape_gripe_info()
            for info in informacoes:
                st.write(info)
        except Exception as e:
            st.error(f"Erro ao carregar informa√ß√µes: {e}")
    
    # Not√≠cias gerais da CNN
    if st.button("Carregar Not√≠cias Gerais"):
        try:
            cnn_news = scrape_cnn_news()
            show_news(cnn_news, "Not√≠cias Gerais sobre gripe - CNN Brasil")
        except Exception as e:
            st.error(f"Erro ao carregar not√≠cias gerais: {e}")
    
    # Not√≠cias por estado e munic√≠pio
    from user_global import MUNICIPIO_USUARIO_GRIPE
    
    if st.button("Carregar Not√≠cias por Munic√≠pio"):
        try:
           
            city_news = scrape_g1_news(MUNICIPIO_USUARIO_GRIPE) if MUNICIPIO_USUARIO_GRIPE else []
            
            
            show_news(city_news, f"Not√≠cias no Munic√≠pio: {MUNICIPIO_USUARIO_GRIPE}")
        except Exception as e:
            st.error(f"Erro ao carregar not√≠cias por estado ou munic√≠pio: {e}")
